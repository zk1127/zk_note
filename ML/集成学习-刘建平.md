## 集成学习-刘建平

### 

- boosting 算法需要解决的四个问题
  - 如何计算学习误差率e?
  - 如何得到弱学习器的权重系数$\alpha$?
  - 如何更新样本权重D?
  - 使用何种结合策略?

### Adaboost

#### 

- 假设训练样本为$T=\{(x_,y_1),(x_2,y_2), ...(x_m,y_m)\}$
- 训练集在第K个弱学习器的输出权重:$D(k) = (w_{k1}, w_{k2}, ...w_{km}) ;\;\; w_{1i}=\frac{1}{m};\;\; i =1,2...m$

#### 二分类问题

##### 如何计算学习误差率e?

- $e_k=P(G_k(x_i) \ne y_i)=\sum_{i=1}^m w_{ki}I(G_k(x_i)\ne y_i)$

##### 如何得到弱学习器的权重系数$\alpha$?

- 如果误差率大,弱学习器的权重将减少,否则将增大

- $\alpha_k=1/2 log \cfrac{1-e_k}{e_k}$

##### 如何更新样本权重D?

- 在第K轮,样本在第K+1个弱分类器中权重增大,如果分类错误,权重将减少
- $w_{k+1,i} = \frac{w_{ki}}{Z_K}exp(-\alpha_ky_iG_k(x_i))$
- 其中 $Z_k = \sum\limits_{i=1}^{m}w_{ki}exp(-\alpha_ky_iG_k(x_i))$

##### 使用何种结合策略?

- 加权表决法
- $f(x) = sign(\sum\limits_{k=1}^{K}\alpha_kG_k(x))$