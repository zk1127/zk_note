## [机器学习算法优缺点](https://zhuanlan.zhihu.com/p/46831267)

#### 总起

- "天下没有免费的午餐",没有一个算法能够完美的解决任何问题
- 偏差与方差
  - 对于绝大多数情况，**高偏差低方差的模型要优于低偏差高方差的模型**，后者会发生过拟合
  - $Bais = E(\hat{f(x)}-f(x))$,预测值的期望与真实值的差距
  - $Var = E(\hat{f(x)} - E(\hat{f(x)}))$,预测值的方差，预测值与其期望的差距

#### 朴素贝叶斯模型

##### 优点

- 其具有坚实的数学基础，稳定的分类效率(最早的垃圾邮件分类器)
- 由于**特征独立假设**，对于大量数据训练也很快
- 对于小规模的数据也能学习的很好，能够适用于增量训练（即可以对增量的样本进行训练）
  - 我对这里的理解是因为其是生成式模型，根据贝叶斯定理，就是**先验+样本=后验**，相当于不断增加样本，他相应的调整后验
- 朴素贝叶斯模型可解释性强（捕捉相关特征能力强）

##### 缺点

- 需要计算先验概率
- **使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好**
  - 例如: 能够学习出: "喜欢成龙演的电影"  和"喜欢周润发的电影"，但是学不出"喜欢成龙和周润发同时演的电影"

##### 主要应用

- 垃圾邮件分类(文本分类)
- 人脸识别(？？？)

#### **Logistic Regression（逻辑回归）**

##### 优点

- 实现简单，广泛的应用于工业问题上；
- 分类的计算量小，速度很快，存储资源低
- 可以便利的观测样本概率分数
- 可以解决多重共线性（增加一个正则项即可）

##### 缺点

- 当特征空间很大时，逻辑回归的性能不是很好，逻辑斯蒂回归是一个广义线性模型(不太能解决高维问题)
- 容易欠拟合，一般准确度不太高（？？？）
- 对于非线性特征需要进行转化

##### 应用领域

- 适用于**根据分类概率排名的领域**，如搜索排名
- 手写识别
- 信用评估

##### 线性回归

##### 优点

- 实现简单
- 对于行满秩或者列满秩的 $X$,可以直接求解。而对于非满秩的X，则需要求奇异值分解

##### 缺点

- 不能拟合非线性数据

#### 最近邻算法-KNN

##### 优点

- 理论成熟，思想简单，既可以用来做分类也可以用来做回归(投票机制)
- 可用于非线性分类
- 训练时间复杂度为O(n)
- 对数据没有假设，准确度高，**对outlier不敏感**
- KNN是一种在线算法，新数据可以直接加入数据集而不必进行重新训练

##### 缺点

- 样本不平衡时效果差(很好理解，他是一种基于投票的算法)
- K值的选取没有理论最优

##### 应用领域

- 文本分类
- 模型识别

#### 决策树

##### 优点

- 决策树易于理解可解释性强，能够进行可视化
- 能够同时处理数值型数据和标签型数据
- 测试数据集时，速度较快(树的遍历)

##### 缺点

- 容易过拟合
- 树分裂的判定标准会影响最终结果
  - 比如ID3倾向于多值属性，C4.5反之
- C4.5只能适用于能够驻留内存的数据集，因为他要做一个归一化

##### 应用

- 企业投资决策(可解释性好)

#### Adaboosting

##### 优点

- Adaboost是一种有很高精度的分类器
- 简单，不用做特征筛选
- 不易发生overfitting

##### 缺点

- 对离群点敏感

#### SVM支持向量机

##### 优点

- 可以解决高维问题
- 可以做小样本机器学习
- 无需依赖整个数据集（支持向量）
- 泛化能力强

##### 缺点

- 当观测样本多的时候，效率不是很高
- 对非线性问题，有时很难找到一个较好的核函数
- 对**缺失数据敏感**
- 常规SVM只能求解二分类问题

##### 核函数选择技巧

- 如果样本数小于特征数，就没必要使用非线性核，直接使用线性核函数即可，也可以先降维再使用非线性核函数
- 反之，可以使用非线性核函数

##### 应用领域

- 文本分类(二分类)

#### 人工神经网络

##### 优点

- 分类准确度高，理论上能拟合任何分布
- 鲁棒性强，具有容错能力

##### 缺点

- 可解释性差
- 需要大量参数学习
- 可能陷入局部极小值

#### K-means 聚类

##### 优点

- 算法原理简单，容易实现
- 当簇是密集的、球状或团状的，且簇与簇之间区别明显时，聚类效果较好

##### 缺点

- 更适合做数值型特征
- 可能收敛到局部极小值
- k难以选择
- 不适合发现非凸面的簇 (DBSCAN)
- 对于噪声敏感

#### 

#### 算法选择参考

- 最先应该使用逻辑斯蒂回归，如果他效果不佳，就将其作为baseline
- 然后再尝试决策树(随机森林)看能否提高模型性能，这里可以做特征选择
- 如果高维问题，可以尝试SVM
- 通常来说，GBDT>=SVM>=RF>=Adaboost>=Other…



#### 终极原则

- 数据>>特征>>模型