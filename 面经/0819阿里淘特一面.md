#### 淘特业务介绍

- 业务内容：淘特用户增长，分为三个维度
  - 权益：红包，月卡，买送
  - 互动：养鸡，种树等
  - 推荐：推荐相关

#### 基础知识

- 使用过那些编程语言？

  - java，Python，C++

- java用过哪些种map？

  - 用过HashMap和TreeMap

- HashMap和TreeMap的区别？

  - HashMap底层是红黑树
  - TreeMap是排序的map

- HashMap和TreeMap查询的时间复杂度差异？

  - 完全忘了，只记得O(1)
  - 这里卡了很久，完全就不记得了

- 递归解决什么问题？

  - 树和图的问题
  - 前n-1的结果会影响n的结果

- 反转链表的递归实现？

  - 卡了n久，要求说一个伪代码

  - ```java
    ListNode reverse(ListNode head) {
        if (head.next == null) return head;
        ListNode last = reverse(head.next);
        head.next.next = head;
        head.next = null;
        return last;
    }
    ```

  - 递归要考虑出口，每一步递归的操作，比如把头节点与下一个节点指向反转

- 机器学习算法熟悉哪些？xgboost和gbdt的区别？

  - GBDT是机器学习算法，XGBoost是该算法的工程实现
  - 在使用CART作为基分类器时，XGBoost显示的加入了正则项来控制模型的复杂度，有利于防止过拟合，从而提高模型的泛化能力，*GBDT是在决策树构建后进行剪枝*
  - GBDT在模型训练过程中只是用代价函数的一阶导数信息，XGBoost对代价函数进行了二阶泰勒展开，可以同时使用一阶和二阶导数信息
  - 传统的GBDT采用CART作为基分类器，XGBoost支持多种类型的基分类器
  - 传统的GBDT每轮迭代都使用了全部数据，XGBoost采用随机森林类似的策略，支持对数据进行采样
  - 传统的GBDT没有对缺失值进行处理，XGBoost能够自动学习缺失值的处理策略

- xgboost的正则化？

  - 在目标函数中，不仅包含了模型的拟合误差函数，还增加了关于每棵树复杂度的惩罚项，即**叶子节点的个数**以及叶子节点分数的平方项，限制了树的复杂度。
  - 像GBDT那样，可以对每个模型乘上一个步长a，a∈(0,1]，用来降低每个模型对预测的贡献。
  - 可以行采样与列采样，与随机森林类似。
  - 缺失值处理：当样本的第i个特征值缺失时，无法利用该特征进行划分时，XGBoost的想法是将该样本分别划分到左结点和右结点，然后计算其增益，哪个大就划分到哪边。

- LR的理解？
  - 提到了交叉熵
  - log对数似然
  
- LR如何正则化？
  - L1正则
  - L2正则
  
- L1正则和L2正则的区别？
  - L1的本质是将误差建模为Laplace分布，L2本质是将误差建模为高斯分布
  - L1不可微
  - L1可以做降维和特征选择
  
- 为什么L1可以降维？

  - 从几何上进行解释

- 有什么熟悉的深度学习模型？

  - GNN，BERT，Transformer

- 推荐相关的算法有了解嘛?

  - 没有

- 无监督的图网络节点嵌入？

  - 只知道deepwork

- GCN和CNN的区别？

  - GCN和CNN都是卷积网络
  - GCN从拉普拉斯变换出发

- BatchNorm？

  - 回答到了过拟合，加速学习

#### 实习与项目

- 会问发什么论文？
- 会问参与的工作量？

#### qa

- 淘特加班严重嘛？
  - 比其他部门严重，高投入，高回报
  - 没有996，下班时间大约9点半到10点

