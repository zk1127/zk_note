### 图神经网络

##### 图神经网络的实用框架

$$
Y = \sigma(\hat D^{-1} \hat A XW)
$$

- X,Y表示输入和输出，$\hat A$表示加了自环的邻接矩阵，$\hat D$是$\hat A$的度矩阵，W表示待训练的参数矩阵
- XW将节点的特征向量进行线性变化
- $\hat A XW$将变化后的节点特征传播到邻居节点
- $\hat D^{-1} \hat A XW$将每个节点收到的特征进行归一化
- $\sigma(\hat D^{-1} \hat A XW)$将归一化的特征进行非线性激活单元

#### 图嵌入技术

##### DeepWalk

- DeepWalk通过**随机游走**(truncated random walk)学习出一个网络的**表示**
- **采样**：通过随机游走对图上的节点进行采样，在给定的时间内得到一个节点构成的序列，论文研究表明从每个节点执行32到64次随机遍历就足够表示节点的结构关系；
- **训练skip-gram**：随机游走得到的节点序列与word2vec方法中的句子相当。文本中skip-gram的输入是一个句子，在这里输入为随机游走采样得到的序列，进一步通过最大化预测相邻节点的概率进行预测周围节点进行训练和学习。 通常预测大约20个邻居节点-左侧10个节点，右侧10个节点。
- **计算嵌入**

##### Node2vec

- Node2vec是DeepWalk的改进版，定义了一个bias random walk的策略生成序列，仍然用skip gram去训练。
- 该算法引入了参数P和Q，参数Q关注随机游走中未发现部分的可能性，即控制着游走是向外还是向内: 若Q>1，随机游走倾向于访问接近的顶点(偏向BFS); 若Q<1，倾向于访问远离的顶点(偏向DFS)。
- 参数P控制了随机游走返回到前一个节点的概率。也就是说，参数P控制节点局部关系的表示，参数Q控制较大邻域的关系。

#####  SDNE

- SDNE没有采用随机游走的方法而是使用自动编码器来同时优化一阶和二阶相似度，学习得到的向量表示保留局部和全局结构，并且对稀疏网络具有鲁棒性。

- 一阶相似度表征了边连接的成对节点之间的局部相似性。 如果网络中的两个节点相连，则认为它们是相似的。

- 二阶相似度表示节点邻域结构的相似性，它能够了表征全局的网络结构。 如果两个节点共享许多邻居，则它们趋于相似
- SDNE的具体做法是使用自动编码器来保持一阶和二阶网络邻近度。它通过联合优化这两个近似值来实现这一点。该方法利用高度非线性函数来获得嵌入。模型由两部分组成：无监督和监督。前者包括一个自动编码器，目的是寻找一个可以重构其邻域的节点的嵌入。后者基于拉普拉斯特征映射，当相似顶点在嵌入空间中彼此映射得很远时，该特征映射会受到惩罚

