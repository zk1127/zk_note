## HMM

### HMM背景

#### HMM 隐马尔可夫模型

![img](../ML/概率图模型/img/hmc.png)

- 定义
  - $\lambda = (\pi,A,B)$
  - $\pi$:初始概率分布
  - A:状态转移矩阵
  - B:发射矩阵
  -  观测变量: o1,o2,...,$o_t$​,... $\rightarrow$​ V={$v_1,v_2,...v_n$​​}
  -  状态变量: i1,i2,...,$i_t$​,... $\rightarrow$​ Q={$q_1,q_2,...q_m$​​​}
  - $A=[a_{ij}],a_{ij}=p(i_{t+1}=q_j|i_t=q_i)$
  - $B=[b_j(k)],b_j(k)=p(O_t=q_k|i_t=q_j)$​​

- 两个假设
  - 观测独立性 $p(i_{t+1}|i_{1},...,i_{t},o_1,...,o_t)=p(i_{t+1}|i_t)$
  - 齐次马尔可夫性$p(o_{t}|i_{1},...,i_{t},o_1,...,o_t)=p(o_{t}|i_t)$

- 三个问题
  - Evaluation：给定$\lambda$,求解$P(O|\lambda)$,前向后向算法
  - Learning：$\lambda$如何求解，EM
  - Decoding: $argmax\;p(I|O)$​
    - 预测:$p(i_{t+1}|o1,o2,...o_t)$
    - 滤波:$p(i_{t}|o1,o2,...o_t)$

#### 前向算法

**求解Evaluation问题：给定$\lambda$,求解$P(O|\lambda)$**

- $p(O|\lambda)=\sum_Ip(I,O|\lambda) = \sum_Ip(O|I,\lambda)P(I|\lambda)$​
- $p(I|\lambda)=p(i_1,i_2,...,i_T|\lambda)=p(i_T|i_1,i_2,...,i_{T-1},\lambda)p(i_1,i_2,...,i_{T-1},\lambda)=\pi(a_{i_1}) \prod_{t=2}^Ta_{i_{t-1}}a_{i_t}$​
- $p(O|I,\lambda)=\prod_{t=1}^Tb_{i_t}(O_t)$
- $p(O|\lambda)=\sum_I\pi(a_{i_1}) \prod_{t=2}^Ta_{i_{t-1}}a_{i_t}\prod_{t=1}^Tb_{i_t}(O_t)$​
- 令$\alpha_t(i)=P(o_1,o_2,...,i_t=q_i|\lambda)$
  - $\alpha_T(i)=P(O,i_t=q_i|\lambda)$
  - $P(O|\lambda)=\sum_{i=1}^Np(O,i_t=q_i|\lambda)=\sum_{i=1}^N \alpha_T(i)$​

- 推导$\alpha_{t+1}(j)$到$\alpha_{t}(i)$
  $$
  \begin{align}
  \alpha_{t+1}(j)
  &= p(o_1,o_2,..,o_{t+1},i_{t+1}=q_j|\lambda)\\
  &= \sum_{i=1}^N p(o_1,o_2,..,o_{t+1},i_{t+1}=q_j,i_{t}=q_i|\lambda)\\
  &= \sum_{i=1}^N p(o_{t+1}|o_1,o_2,..,o_{t},i_{t+1}=q_j,i_{t}=q_i|\lambda)p(o_1,...,o_t,i_t=q_i,i_{t+1}=q_j|\lambda)\\
  &= \sum_{i=1}^N p(o_{t+1}|i_{t+1}=q_j)p(i_{t+1}=q_j|o_1,o_2,..,o_{t},i_{t}=q_j,i_{t}=q_i|\lambda)p(o_1,...o_t，i_t=q_i|\lambda)\\
  &=\sum_{i=1}^Np(o_{t+1}|i_{t+1})p(i_{t+1}=q_j|i_t=q_i,\lambda)\alpha_t(i)
  \end{align}
  $$
  

#### 后向算法

- 引入$\beta_t(i)=P(o_{t+1},...,o_{T}|i_t=q_i,\lambda)$​

  - $\beta_1(i)=P(o_{2},...,o_{T}|i_t=q_i,\lambda)$

  - $P(O|\lambda)$与$\beta_t(i)$​的关系

  - $$
    \begin{align}
    P(O|\lambda)
    &= P(o_1,..,o_T|\lambda)\\
    &= \sum_{i=1}^N p(o_1,...,o_T,i_t=q_i)\\
    &= \sum_{i=1}^N p(o_1,...,o_T|i_t=q_i)p(i_t=q_i)\\
    &= \sum_{i=1}^N p(o_1|o_2...,o_T|i_t=q_i)p(o_2,...,o_T|i_t=q_i)p(i_t=q_i)\\
    &= \sum_{i=1}^N p(o_1|i_1=q_i) \beta_1(i) p(i_t=q_i)\\
    &= b_i(o_1) \beta_1(i) p(i_t=q_i)
    \end{align}
    $$

  - $\beta_{t}(i)$​的递推式

  - $$
    \begin{align}
    \beta_t(i)
    &=P(o_{t+1},...,o_{T}|i_t=q_i)\\
    &= \sum_{j=1}^N P(o_{t+1},...,o_{T},i_{t+1}=q_j|i_t=q_i)\\
    &= \sum_{j=1}^N P(o_{t+1},...,o_{T},i_{t+1}=q_j|i_{t+1} =q_j,i_t=q_i)P(i_{t+1}=q_j|i_{t}=q_i) \\
    &= \sum_{j=1}^N P(o_{t+1},...,o_{T}|i_{t+1}=q_j)a_{ij}\\
    &= \sum_{j=1}^N P(o_{t+1}|o_{t+2},...o_T,i_{t+1}=q_j)P(o_{t+2},...,o_{T}|i_{t+1}=q_j)a_{ij}\\
    &=\sum_{j=1}^N b_j(o_{t+1}) \beta_{t+1}(j)a_{ij} 
    \end{align}
    $$

    

