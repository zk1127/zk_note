## 指数族分布

**高斯分布，伯努利分布，二项分布...**

- 指数族分布的定义

  - 

  $$
  \begin{align}
  p(x|\eta)
  &=h(x)exp(\eta^T\phi(x)-A(\eta))\\
  &=h(x)exp(\eta^T\phi(x))exp(-A(\eta))\\
  &=\cfrac{1}{exp(A(\eta))}h(x)exp(\eta^T\phi(x))
  \end{align}
  $$

  - $A(\eta)$：log  partition function (partition function: 配分函数)
  - $\eta$：参数
  - $\phi(x)$:充分统计量

- 指数族分布的特点

  - 充分统计量:$\phi(x)$，统计量本身包含所有的分布信息，包括分布的未知参数 
    - 有利于online learning，起到了压缩数据的作用
    - 统计量：样本均值，样本方差，标准差等
  - 共轭
    - $p(z|x) \propto p(x|z)p(z)$,如果$p(x|z)$和$p(z)$为共轭分布，那么$p(z|x)$就与$p(z)$属于同一类分布
      - 例如，如果$p(x|z)$和$p(z)$分别为二项分布和beta分布，那么$p(z|x)$也属于beta分布
  - 最大熵
    - 无信息先验
    - 最大熵原理：在给出的限定条件（数据）下，**在所有可能的概率模型(分布) 中，熵最大的模型是最好的模型(分布)**
  - 广义线性模型
    - 线性组合:$w^Tx$
    - link function
    - 指数族分布
  - 变分推断
  - 概率图模型

#### Gaussian 分布

- 。。

#### 充分统计量和log 配分函数

- $$
  A^`(\eta)=E_{p(x|\eta)}[\phi(x)]\\
  A^{``}(\eta) = Var[\phi(x)]
  $$

#### 极大似然估计和充分统计量

- $A^{`}(\eta_{MLE})=\cfrac{1}{N}\sum_{i=1}^N \phi(x_i)$

#### 最大熵角度

- 信息量： $-log p$
- 熵：$- \sum_{i=1}^N p_ilogp_i$,可以描述等可能性
- 一个数据集$D$，在这个数据集上的经验分布为 $\hat{p}(x)=\cfrac{Count(x)}{N}$，实际不可能满足所有的经验概率相同，于是在上面的最大熵原理中还需要加入这个经验分布的约束。
  - 对任意一个函数，经验分布的经验期望可以求得为：
    - $$E_{\hat{p}}[f(x)]=\Delta$$

- 最大熵原理的公式化

- $$
  min \sum_{x}p(x)logp(x)\\
  s.t. \sum_{x}p(x)=1\\
  s.t. E_{p}[f(x)] = E_{\hat{p}}[f(x)] = \Delta
  $$

  

